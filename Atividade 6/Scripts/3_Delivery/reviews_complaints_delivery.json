{
	"jobConfig": {
		"name": "reviews_complaints_delivery",
		"description": "",
		"role": "arn:aws:iam::859900066986:role/LabRole",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "reviews_complaints_delivery.py",
		"scriptLocation": "s3://aws-glue-assets-859900066986-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-08-31T02:26:16.477Z",
		"developerMode": true,
		"connectionsList": [
			"Mysql"
		],
		"temporaryDirectory": "s3://aws-glue-assets-859900066986-us-east-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": false,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-859900066986-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\n\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\n\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\n\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\nrds_url = \"jdbc:mysql://glassdoor-db.cluster-chklsxhwihzi.us-east-1.rds.amazonaws.com:3306/glassdoor-db\"\r\nrds_properties = {\r\n    \"user\": \"admin\",\r\n    \"password\": \"#EDCvfr45tgb\",\r\n    \"driver\": \"com.mysql.cj.jdbc.Driver\"\r\n}\r\n\r\n\r\ndf_complaints = spark.read.jdbc(url=rds_url, table=\"complaints_trusted\", properties=rds_properties)\r\ndf_reviews = spark.read.jdbc(url=rds_url, table=\"employees_trusted\", properties=rds_properties)\r\n\r\ndf_target_table = (df_complaints.join(df_reviews, df_complaints.INSTITUTION_NAME == df_reviews.INSTITUTION_NAME, \"inner\")\r\n                                .select(df_complaints.YEAR,\r\n                                        df_complaints.QUARTER,\r\n                                        df_complaints.INSTITUTION_CATEGORY,\r\n                                        df_complaints.INSTITUTION_TYPE,\r\n                                        df_complaints.CNPJ,\r\n                                        df_complaints.INSTITUTION_NAME,\r\n                                        df_complaints.QTY_JUSTIFIED_REGULATED_COMPLAINTS,\r\n                                        df_complaints.QTY_OTHER_REGULATED_COMPLAINTS,\r\n                                        df_complaints.QTY_NOT_REGULATED_COMPLAINTS,\r\n                                        df_complaints.QTY_COMPLAINTS,\r\n                                        df_reviews.REVIEWS_COUNT,\r\n                                        df_reviews.OVERALL_RATING))\r\n\r\ntarget_table = \"reviews_complaints_delivery\"\r\n\r\ndf_target_table.write.jdbc(url=rds_url, table=target_table, mode=\"overwrite\", properties=rds_properties)\r\n\r\njob.commit()"
}